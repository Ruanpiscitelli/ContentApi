version: '3.8'

# Configurações comuns para todos os serviços
x-common-settings: &common-settings
  restart: unless-stopped
  init: true
  security_opt:
    - no-new-privileges:true
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
    interval: 30s
    timeout: 10s
    retries: 3
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"

# Variáveis de ambiente comuns
x-common-env: &common-env
  PYTHONPATH: /app
  PYTHONUNBUFFERED: 1
  TRANSFORMERS_CACHE: /app/cache/transformers
  HF_HOME: /app/cache/huggingface

# Configuração padrão de recursos
x-resources: &service-resources
  limits:
    cpus: '4'
    memory: 16G
  reservations:
    devices:
      - driver: nvidia
        count: 1
        capabilities: [gpu, utility, compute]

x-gpu-settings: &gpu-settings
  runtime: nvidia
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]

x-volumes: &common-volumes
  - ./models:/app/models:ro
  - ./logs:/app/logs
  - ./cache:/app/cache
  - ./uploads:/app/uploads
  - ./temp:/app/temp

services:
  base:
    build:
      context: ./meu-servidor-ia
      dockerfile: Dockerfile.base
    image: contentapi-base

  video-generator:
    <<: [*common-settings, *gpu-settings]
    build:
      context: ./meu-servidor-ia
      dockerfile: services/video_generator/Dockerfile
    volumes:
      - ./models:/app/models:ro
      - ./storage:/app/storage
      - ./logs/video:/app/logs
      - ./cache:/app/cache
    ports:
      - "8003:8000"
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
    depends_on:
      - base

  image-generator:
    <<: [*common-settings, *gpu-settings]
    build:
      context: ./meu-servidor-ia
      dockerfile: services/image_generator/Dockerfile
    volumes:
      - ./models:/app/models:ro
      - ./storage:/app/storage
      - ./logs/image:/app/logs
      - ./cache:/app/cache
    ports:
      - "8002:8000"
    environment:
      - NVIDIA_VISIBLE_DEVICES=1
      - CUDA_VISIBLE_DEVICES=1
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
    depends_on:
      - base

  text-generation:
    <<: [*common-settings, *gpu-settings]
    build:
      context: ./meu-servidor-ia
      dockerfile: services/text_generation/Dockerfile
    volumes:
      - ./models:/app/models:ro
      - ./storage:/app/storage
      - ./logs/text:/app/logs
      - ./cache:/app/cache
    ports:
      - "8004:8000"
    environment:
      - NVIDIA_VISIBLE_DEVICES=2
      - CUDA_VISIBLE_DEVICES=2
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
    depends_on:
      - base

  voice-generator:
    <<: [*common-settings, *gpu-settings]
    build:
      context: ./meu-servidor-ia
      dockerfile: services/voice_generator/Dockerfile
    volumes:
      - ./models:/app/models:ro
      - ./storage:/app/storage
      - ./logs/voice:/app/logs
      - ./cache:/app/cache
    ports:
      - "8005:8000"
    environment:
      - NVIDIA_VISIBLE_DEVICES=3
      - CUDA_VISIBLE_DEVICES=3
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
    depends_on:
      - base

  video-editor:
    <<: *common-settings
    build:
      context: .
      dockerfile: meu-servidor-ia/services/video_editor/Dockerfile
    volumes:
      - ./cache:/app/cache
      - ./logs:/app/logs
      - ./uploads:/app/uploads
    environment:
      - PYTHONPATH=/app
      - TRANSFORMERS_CACHE=/app/cache/transformers
      - HF_HOME=/app/cache/huggingface
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "8005:8000"

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  dashboard:
    <<: *common-settings
    build:
      context: ./meu-servidor-ia
      dockerfile: services/dashboard/Dockerfile
      args:
        PYTHON_VERSION: "3.10"
        USER_NAME: appuser
        USER_UID: 1000
        USER_GID: 1000
    ports:
      - "8000:8000"
    environment:
      <<: *common-env
      API_HOST: 0.0.0.0
      API_PORT: 8000
    depends_on:
      - video-generator
      - image-generator
      - text-generation
      - voice-generator
      - video-editor

networks:
  default:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/24

volumes:
  redis_data: 